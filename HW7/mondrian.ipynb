{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding:utf-8\n",
    "\"\"\"\n",
    "main module of mondrian\n",
    "\"\"\"\n",
    "\n",
    "# Implemented by Qiyuan Gong\n",
    "# qiyuangong@gmail.com\n",
    "# 2014-09-11\n",
    "\n",
    "# @InProceedings{LeFevre2006,\n",
    "#   Title = {Mondrian Multidimensional K-Anonymity},\n",
    "#   Author = {LeFevre, Kristen and DeWitt, David J. and Ramakrishnan, Raghu},\n",
    "#   Booktitle = {ICDE '06: Proceedings of the 22nd International Conference on Data Engineering},\n",
    "#   Year = {2006},\n",
    "#   Address = {Washington, DC, USA},\n",
    "#   Pages = {25},\n",
    "#   Publisher = {IEEE Computer Society},\n",
    "#   Doi = {http://dx.doi.org/10.1109/ICDE.2006.101},\n",
    "#   ISBN = {0-7695-2570-9},\n",
    "# }\n",
    "\n",
    "# !/usr/bin/env python\n",
    "# coding=utf-8\n",
    "\n",
    "import pdb\n",
    "import time\n",
    "from utils.utility import cmp_value, value, merge_qi_value\n",
    "from functools import cmp_to_key\n",
    "\n",
    "# warning all these variables should be re-inited, if\n",
    "# you want to run mondrian with different parameters\n",
    "__DEBUG = False\n",
    "QI_LEN = 10\n",
    "GL_K = 0\n",
    "RESULT = []\n",
    "QI_RANGE = []\n",
    "QI_DICT = []\n",
    "QI_ORDER = []\n",
    "\n",
    "\n",
    "class Partition(object):\n",
    "\n",
    "    \"\"\"\n",
    "    Class for Group (or EC), which is used to keep records\n",
    "    self.member: records in group\n",
    "    self.low: lower point, use index to avoid negative values\n",
    "    self.high: higher point, use index to avoid negative values\n",
    "    self.allow: show if partition can be split on this QI\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, low, high):\n",
    "        \"\"\"\n",
    "        split_tuple = (index, low, high)\n",
    "        \"\"\"\n",
    "        self.low = list(low)\n",
    "        self.high = list(high)\n",
    "        self.member = data[:]\n",
    "        self.allow = [1] * QI_LEN\n",
    "\n",
    "    def add_record(self, record, dim):\n",
    "        \"\"\"\n",
    "        add one record to member\n",
    "        \"\"\"\n",
    "        self.member.append(record)\n",
    "\n",
    "    def add_multiple_record(self, records, dim):\n",
    "        \"\"\"\n",
    "        add multiple records (list) to partition\n",
    "        \"\"\"\n",
    "        for record in records:\n",
    "            self.add_record(record, dim)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        return number of records\n",
    "        \"\"\"\n",
    "        return len(self.member)\n",
    "\n",
    "\n",
    "def get_normalized_width(partition, index):\n",
    "    \"\"\"\n",
    "    return Normalized width of partition\n",
    "    similar to NCP\n",
    "    \"\"\"\n",
    "    d_order = QI_ORDER[index]\n",
    "    width = value(d_order[partition.high[index]]) - value(d_order[partition.low[index]])\n",
    "    if width == QI_RANGE[index]:\n",
    "        return 1\n",
    "    return width * 1.0 / QI_RANGE[index]\n",
    "\n",
    "\n",
    "def choose_dimension(partition):\n",
    "    \"\"\"\n",
    "    choose dim with largest norm_width from all attributes.\n",
    "    This function can be upgraded with other distance function.\n",
    "    \"\"\"\n",
    "    max_width = -1\n",
    "    max_dim = -1\n",
    "    for dim in range(QI_LEN):\n",
    "        if partition.allow[dim] == 0:\n",
    "            continue\n",
    "        norm_width = get_normalized_width(partition, dim)\n",
    "        if norm_width > max_width:\n",
    "            max_width = norm_width\n",
    "            max_dim = dim\n",
    "    if max_width > 1:\n",
    "        pdb.set_trace()\n",
    "    return max_dim\n",
    "\n",
    "\n",
    "def frequency_set(partition, dim):\n",
    "    \"\"\"\n",
    "    get the frequency_set of partition on dim\n",
    "    \"\"\"\n",
    "    frequency = {}\n",
    "    for record in partition.member:\n",
    "        try:\n",
    "            frequency[record[dim]] += 1\n",
    "        except KeyError:\n",
    "            frequency[record[dim]] = 1\n",
    "    return frequency\n",
    "\n",
    "\n",
    "def find_median(partition, dim):\n",
    "    \"\"\"\n",
    "    find the middle of the partition, return split_val\n",
    "    \"\"\"\n",
    "    # use frequency set to get median\n",
    "    frequency = frequency_set(partition, dim)\n",
    "    split_val = ''\n",
    "    next_val = ''\n",
    "    value_list = list(frequency.keys())\n",
    "    value_list.sort(key=cmp_to_key(cmp_value))\n",
    "    total = sum(frequency.values())\n",
    "    middle = total // 2\n",
    "    if middle < GL_K or len(value_list) <= 1:\n",
    "        try:\n",
    "            return '', '', value_list[0], value_list[-1]\n",
    "        except IndexError:\n",
    "            return '', '', '', ''\n",
    "    index = 0\n",
    "    split_index = 0\n",
    "    for i, qi_value in enumerate(value_list):\n",
    "        index += frequency[qi_value]\n",
    "        if index >= middle:\n",
    "            split_val = qi_value\n",
    "            split_index = i\n",
    "            break\n",
    "    else:\n",
    "        print(\"Error: cannot find split_val\")\n",
    "    try:\n",
    "        next_val = value_list[split_index + 1]\n",
    "    except IndexError:\n",
    "        # there is a frequency value in partition\n",
    "        # which can be handle by mid_set\n",
    "        # e.g.[1, 2, 3, 4, 4, 4, 4]\n",
    "        next_val = split_val\n",
    "    return (split_val, next_val, value_list[0], value_list[-1])\n",
    "\n",
    "\n",
    "def anonymize_strict(partition):\n",
    "    \"\"\"\n",
    "    recursively partition groups until not allowable\n",
    "    \"\"\"\n",
    "    allow_count = sum(partition.allow)\n",
    "    # only run allow_count times\n",
    "    if allow_count == 0:\n",
    "        RESULT.append(partition)\n",
    "        return\n",
    "    for index in range(allow_count):\n",
    "        # choose attrubite from domain\n",
    "        dim = choose_dimension(partition)\n",
    "        if dim == -1:\n",
    "            print(\"Error: dim=-1\")\n",
    "            pdb.set_trace()\n",
    "        (split_val, next_val, low, high) = find_median(partition, dim)\n",
    "        # Update parent low and high\n",
    "        if low is not '':\n",
    "            partition.low[dim] = QI_DICT[dim][low]\n",
    "            partition.high[dim] = QI_DICT[dim][high]\n",
    "        if split_val == '' or split_val == next_val:\n",
    "            # cannot split\n",
    "            partition.allow[dim] = 0\n",
    "            continue\n",
    "        # split the group from median\n",
    "        mean = QI_DICT[dim][split_val]\n",
    "        lhs_high = partition.high[:]\n",
    "        rhs_low = partition.low[:]\n",
    "        lhs_high[dim] = mean\n",
    "        rhs_low[dim] = QI_DICT[dim][next_val]\n",
    "        lhs = Partition([], partition.low, lhs_high)\n",
    "        rhs = Partition([], rhs_low, partition.high)\n",
    "        for record in partition.member:\n",
    "            pos = QI_DICT[dim][record[dim]]\n",
    "            if pos <= mean:\n",
    "                # lhs = [low, mean]\n",
    "                lhs.add_record(record, dim)\n",
    "            else:\n",
    "                # rhs = (mean, high]\n",
    "                rhs.add_record(record, dim)\n",
    "        # check is lhs and rhs satisfy k-anonymity\n",
    "        if len(lhs) < GL_K or len(rhs) < GL_K:\n",
    "            partition.allow[dim] = 0\n",
    "            continue\n",
    "        # anonymize sub-partition\n",
    "        anonymize_strict(lhs)\n",
    "        anonymize_strict(rhs)\n",
    "        return\n",
    "    RESULT.append(partition)\n",
    "\n",
    "\n",
    "def anonymize_relaxed(partition):\n",
    "    \"\"\"\n",
    "    recursively partition groups until not allowable\n",
    "    \"\"\"\n",
    "    if sum(partition.allow) == 0:\n",
    "        # can not split\n",
    "        RESULT.append(partition)\n",
    "        return\n",
    "    # choose attribute from domain\n",
    "    dim = choose_dimension(partition)\n",
    "    if dim == -1:\n",
    "        print(\"Error: dim=-1\")\n",
    "        pdb.set_trace()\n",
    "    # use frequency set to get median\n",
    "    (split_val, next_val, low, high) = find_median(partition, dim)\n",
    "    # Update parent low and high\n",
    "    if low is not '':\n",
    "        partition.low[dim] = QI_DICT[dim][low]\n",
    "        partition.high[dim] = QI_DICT[dim][high]\n",
    "    if split_val == '':\n",
    "        # cannot split\n",
    "        partition.allow[dim] = 0\n",
    "        anonymize_relaxed(partition)\n",
    "        return\n",
    "    # split the group from median\n",
    "    mean = QI_DICT[dim][split_val]\n",
    "    lhs_high = partition.high[:]\n",
    "    rhs_low = partition.low[:]\n",
    "    lhs_high[dim] = mean\n",
    "    rhs_low[dim] = QI_DICT[dim][next_val]\n",
    "    lhs = Partition([], partition.low, lhs_high)\n",
    "    rhs = Partition([], rhs_low, partition.high)\n",
    "    mid_set = []\n",
    "    for record in partition.member:\n",
    "        pos = QI_DICT[dim][record[dim]]\n",
    "        if pos < mean:\n",
    "            # lhs = [low, mean)\n",
    "            lhs.add_record(record, dim)\n",
    "        elif pos > mean:\n",
    "            # rhs = (mean, high]\n",
    "            rhs.add_record(record, dim)\n",
    "        else:\n",
    "            # mid_set keep the means\n",
    "            mid_set.append(record)\n",
    "    # handle records in the middle\n",
    "    # these records will be divided evenly\n",
    "    # between lhs and rhs, such that\n",
    "    # |lhs| = |rhs| (+1 if total size is odd)\n",
    "    half_size = len(partition) // 2\n",
    "    for i in range(half_size - len(lhs)):\n",
    "        record = mid_set.pop()\n",
    "        lhs.add_record(record, dim)\n",
    "    if len(mid_set) > 0:\n",
    "        rhs.low[dim] = mean\n",
    "        rhs.add_multiple_record(mid_set, dim)\n",
    "    # It's not necessary now.\n",
    "    # if len(lhs) < GL_K or len(rhs) < GL_K:\n",
    "    #     print \"Error: split failure\"\n",
    "    # anonymize sub-partition\n",
    "    anonymize_relaxed(lhs)\n",
    "    anonymize_relaxed(rhs)\n",
    "\n",
    "\n",
    "def init(data, k, QI_num=-1):\n",
    "    \"\"\"\n",
    "    reset global variables\n",
    "    \"\"\"\n",
    "    global GL_K, RESULT, QI_LEN, QI_DICT, QI_RANGE, QI_ORDER\n",
    "    if QI_num <= 0:\n",
    "        QI_LEN = len(data[0]) - 1\n",
    "    else:\n",
    "        QI_LEN = QI_num\n",
    "    GL_K = k\n",
    "    RESULT = []\n",
    "    # static values\n",
    "    QI_DICT = []\n",
    "    QI_ORDER = []\n",
    "    QI_RANGE = []\n",
    "    att_values = []\n",
    "    for i in range(QI_LEN):\n",
    "        att_values.append(set())\n",
    "        QI_DICT.append(dict())\n",
    "    for record in data:\n",
    "        for i in range(QI_LEN):\n",
    "            att_values[i].add(record[i])\n",
    "    for i in range(QI_LEN):\n",
    "        value_list = list(att_values[i])\n",
    "        value_list.sort(key=cmp_to_key(cmp_value))\n",
    "        QI_RANGE.append(value(value_list[-1]) - value(value_list[0]))\n",
    "        QI_ORDER.append(list(value_list))\n",
    "        for index, qi_value in enumerate(value_list):\n",
    "            QI_DICT[i][qi_value] = index\n",
    "\n",
    "\n",
    "def mondrian(data, k, relax=False, QI_num=-1):\n",
    "    \"\"\"\n",
    "    Main function of mondrian, return result in tuple (result, (ncp, rtime)).\n",
    "    data: dataset in 2-dimensional array.\n",
    "    k: k parameter for k-anonymity\n",
    "    QI_num: Default -1, which exclude the last column. Othewise, [0, 1,..., QI_num - 1]\n",
    "            will be anonymized, [QI_num,...] will be excluded.\n",
    "    relax: determine use strict or relaxed mondrian,\n",
    "    Both mondrians split partition with binary split.\n",
    "    In strict mondrian, lhs and rhs have not intersection.\n",
    "    But in relaxed mondrian, lhs may be have intersection with rhs.\n",
    "    \"\"\"\n",
    "    init(data, k, QI_num)\n",
    "    result = []\n",
    "    data_size = len(data)\n",
    "    low = [0] * QI_LEN\n",
    "    high = [(len(t) - 1) for t in QI_ORDER]\n",
    "    whole_partition = Partition(data, low, high)\n",
    "    # begin mondrian\n",
    "    start_time = time.time()\n",
    "    if relax:\n",
    "        # relax model\n",
    "        anonymize_relaxed(whole_partition)\n",
    "    else:\n",
    "        # strict model\n",
    "        anonymize_strict(whole_partition)\n",
    "    rtime = float(time.time() - start_time)\n",
    "    # generalization result and\n",
    "    # evaluation information loss\n",
    "    ncp = 0.0\n",
    "    dp = 0.0\n",
    "    for partition in RESULT:\n",
    "        rncp = 0.0\n",
    "        for index in range(QI_LEN):\n",
    "            rncp += get_normalized_width(partition, index)\n",
    "        rncp *= len(partition)\n",
    "        ncp += rncp\n",
    "        dp += len(partition) ** 2\n",
    "        for record in partition.member[:]:\n",
    "            for index in range(QI_LEN):\n",
    "                record[index] = merge_qi_value(QI_ORDER[index][partition.low[index]],\n",
    "                                QI_ORDER[index][partition.high[index]])\n",
    "            result.append(record)\n",
    "    # If you want to get NCP values instead of percentage\n",
    "    # please remove next three lines\n",
    "    ncp /= QI_LEN\n",
    "    ncp /= data_size\n",
    "    ncp *= 100\n",
    "    if __DEBUG:\n",
    "        from decimal import Decimal\n",
    "        print(\"Discernability Penalty=%.2E\" % Decimal(str(dp)))\n",
    "        print(\"size of partitions=%d\" % len(RESULT))\n",
    "        print(\"K=%d\" % k)\n",
    "        print(\"NCP = %.2f %%\" % ncp)\n",
    "    return (result, (ncp, rtime))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
